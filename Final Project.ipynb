{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Tweets: Project Intro\n",
    "### For this project, we will be using this data set of twitter post text, found on kaggle. The goal is to come up with an algorithm that most accuractely classifies a tweet as indicative of a real disaster or not a real disaster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we will read in the \"train\" dataset, which contains the correct labels. We will split the data 50/50 between train and dev (or test). For ease of analysis and text processing, the data will be further split into \"pos\" (label = 1) and \"neg\" (label = 0) dataframes and text only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some data metrics\n",
      "\n",
      "Shape of train data: (3806, 5)\n",
      "\n",
      "Missing data in each column:\n",
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "\n",
      "Number of disaster tweets:\n",
      "0    2252\n",
      "1    1554\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#read in data\n",
    "df = pd.read_csv(r'C:\\Users\\lwu31\\OneDrive - JNJ\\Documents\\train.csv')\n",
    "\n",
    "#50/50 split between train and dev\n",
    "numtest = int(len(df)/2)\n",
    "df_train = df[:numtest]\n",
    "df_dev = df[numtest:]\n",
    "train_data, train_label = df_train.text, df_train.target\n",
    "dev_data, dev_label = df_dev.text, df_dev.target\n",
    "\n",
    "#split into disaster and non disaster data\n",
    "df_neg = df_train.loc[df_train.target == 0]\n",
    "df_pos = df_train.loc[df_train.target == 1]\n",
    "\n",
    "#split into disaster and nondisaster tweets only\n",
    "neg_text = df_neg.text\n",
    "pos_text = df_pos.text\n",
    "\n",
    "print(\"Some data metrics\\n\")\n",
    "print(\"Shape of train data:\", df_train.shape)\n",
    "print(\"\\nMissing data in each column:\\n\" + str(df.isnull().sum()))\n",
    "print(\"\\nNumber of disaster tweets:\\n\"+ str(train_labels.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because the available tags, keyword and location, are sparse and method of construction are unclear to us, we wanted to create new tags for the text that we may be able to train later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
      "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
      "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
      "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
      "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
      "\n",
      "   target                         hashtag rt link mentions links  retweet  \\\n",
      "0       1                    [earthquake]               []    []    False   \n",
      "1       1                              []               []    []    False   \n",
      "2       1                              []               []    []    False   \n",
      "3       1                     [wildfires]               []    []    False   \n",
      "4       1             [Alaska, wildfires]               []    []    False   \n",
      "5       1  [RockyFire, CAfire, wildfires]               []    []    False   \n",
      "6       1               [flood, disaster]               []    []    False   \n",
      "7       1                              []               []    []    False   \n",
      "8       1                              []               []    []    False   \n",
      "9       1                              []               []    []    False   \n",
      "\n",
      "   mentions_ind  hashtag_ind  links_ind  retweet_ind  \n",
      "0             0            1          0            0  \n",
      "1             0            0          0            0  \n",
      "2             0            0          0            0  \n",
      "3             0            1          0            0  \n",
      "4             0            1          0            0  \n",
      "5             0            1          0            0  \n",
      "6             0            1          0            0  \n",
      "7             0            0          0            0  \n",
      "8             0            0          0            0  \n",
      "9             0            0          0            0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-1b8440946814>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['hashtag'] = df_train['text'].apply(lambda s: re.findall(r'#(\\w+)', s))\n",
      "<ipython-input-24-1b8440946814>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['mentions'] = df_train['text'].apply(lambda x: re.findall(r\"@(\\w+)\", x))\n",
      "<ipython-input-24-1b8440946814>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['links'] = df_train['text'].apply(lambda x: re.findall(r\"http:\\/\\/(\\w+)\", x))\n",
      "<ipython-input-24-1b8440946814>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['retweet'] = df_train['text'].apply(lambda x: \"rt\" in x.lower().split())\n",
      "<ipython-input-24-1b8440946814>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['mentions_ind'] = df_train.mentions.apply(lambda y: 0 if len(y)==0 else 1)\n",
      "<ipython-input-24-1b8440946814>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['hashtag_ind'] = df_train.hashtag.apply(lambda y: 0 if len(y)==0 else 1)\n",
      "<ipython-input-24-1b8440946814>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['links_ind'] = df_train.links.apply(lambda y: 0 if len(y)==0 else 1)\n",
      "<ipython-input-24-1b8440946814>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['retweet_ind'] = df_train.retweet.apply(lambda y: 0 if y == False else 1)\n"
     ]
    }
   ],
   "source": [
    "df_train['hashtag'] = df_train['text'].apply(lambda s: re.findall(r'#(\\w+)', s))\n",
    "df_train['mentions'] = df_train['text'].apply(lambda x: re.findall(r\"@(\\w+)\", x))\n",
    "df_train['links'] = df_train['text'].apply(lambda x: re.findall(r\"http:\\/\\/(\\w+)\", x))\n",
    "df_train['retweet'] = df_train['text'].apply(lambda x: \"rt\" in x.lower().split())\n",
    "\n",
    "df_train['mentions_ind'] = df_train.mentions.apply(lambda y: 0 if len(y)==0 else 1)\n",
    "df_train['hashtag_ind'] = df_train.hashtag.apply(lambda y: 0 if len(y)==0 else 1)\n",
    "df_train['links_ind'] = df_train.links.apply(lambda y: 0 if len(y)==0 else 1)\n",
    "df_train['retweet_ind'] = df_train.retweet.apply(lambda y: 0 if y == False else 1)\n",
    "\n",
    "print(df_train.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In text classification problems, text pre-processing is a crucial part to prepping our data for analysis. This can be found in our text_clean function. Some pre-processing considerations we have made include:\n",
    "* removing numbers, symbols, and punctuation\n",
    "* standardizing to lowercase text\n",
    "* remove stop words\n",
    "* word stemming\n",
    "* more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(text):\n",
    "  #remove line breaks\n",
    "  text = re.sub(r\"\\n\",\"\",text)\n",
    "\n",
    "  #convert to lowercase \n",
    "  text = text.lower()\n",
    "\n",
    "  #remove digits and currencies \n",
    "  text = re.sub(r\"\\d+\",\"\",text) \n",
    "  text = re.sub(r'[\\$\\d+\\d+\\$]', \"\", text)      \n",
    "\n",
    "  #remove dates \n",
    "  text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "  text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "  text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "\n",
    "  #remove non-ascii\n",
    "  text = re.sub(r'[^\\x00-\\x7f]',r' ',text) \n",
    "\n",
    "  #remove punctuation\n",
    "  text = re.sub(r'[^\\w\\s]','',text) \n",
    "\n",
    "  #remove hyperlinks\n",
    "  text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "\n",
    "  #replace extra whitespaces with a single one \n",
    "  #text = re.sub(re.sub(' +', ' ', text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the data has been cleaned and text pre-processed, we can begin exploring different algorithms. The three machine learning algorithms we will focus on are:\n",
    "* Naive Bayes\n",
    "* Logistic Regression\n",
    "* SVM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
