{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acbe2505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geonamescache in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: nltk in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (3.6.3)\n",
      "Requirement already satisfied: joblib in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: regex in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from nltk) (2021.8.28)\n",
      "Requirement already satisfied: wordcloud in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from wordcloud) (1.21.2)\n",
      "Requirement already satisfied: pillow in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from wordcloud) (8.3.1)\n",
      "Requirement already satisfied: matplotlib in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six in /Users/benjamin.mok/berkeley/w207/env/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1076)>\n",
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1076)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1076)>\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ef093495e531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# WordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "!pip install geonamescache\n",
    "!pip install nltk\n",
    "!pip install wordcloud\n",
    "\n",
    "# General libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# SK-learn libraries for feature extraction from text\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# NLP processors\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, sent_tokenize, FreqDist\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "# WordCloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7126db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some data metrics\n",
      "\n",
      "Shape of train data: (6091, 5)\n",
      "\n",
      "Missing data in each column:\n",
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "\n",
      "Number of disaster tweets:\n",
      "0    3396\n",
      "1    2695\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#read in data\n",
    "# df = pd.read_csv(r'C:\\Users\\lwu31\\OneDrive - JNJ\\Documents\\train.csv')\n",
    "df = pd.read_csv('data/nlp-getting-started/train.csv')\n",
    "# sample the data, acts as shuffling the data on row\n",
    "\n",
    "#50/50 split between train and dev\n",
    "# allocate more for traiing if we do it this way, i'll run some\n",
    "# analysis to see if my cluster bootstrap can imrpove the models we run.\n",
    "numtest = int(len(df)/5)\n",
    "df_train = df[numtest:].reset_index(drop=True)\n",
    "df_test = df[:numtest].reset_index(drop=True)\n",
    "\n",
    "train_data, train_label = df_train.text, df_train.target\n",
    "test_data, test_label = df_test.text, df_test.target\n",
    "\n",
    "#split into disaster and non disaster data\n",
    "df_neg = df_train.loc[df_train.target == 0]\n",
    "df_pos = df_train.loc[df_train.target == 1]\n",
    "\n",
    "#split into disaster and nondisaster tweets only\n",
    "neg_text = df_neg.text\n",
    "pos_text = df_pos.text\n",
    "\n",
    "print(\"Some data metrics\\n\")\n",
    "print(\"Shape of train data:\", df_train.shape)\n",
    "print(\"\\nMissing data in each column:\\n\" + str(df.isnull().sum()))\n",
    "print(\"\\nNumber of disaster tweets:\\n\"+ str(train_label.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37cfe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data prior to running the model using this function\n",
    "# TODO: Here I've commented out the punctuation regex section\n",
    "# Feel free to uncomment that part BUT I think we should leave it out\n",
    "# altogether. See below for usage.\n",
    "\n",
    "def preprocess(text, method=None, tokenizer=sent_tokenize, rm_stop=False): \n",
    "    \"\"\"Returns a text processed string.\n",
    "\n",
    "    Arguments:\n",
    "    text      -- String, func is designed for loops\n",
    "    \n",
    "    method    -- ('s','l') Specify from s - stemmatize, l - lemmatize.\n",
    "                 None will mean you do not want to remove suffix.\n",
    "                 \n",
    "    tokenizer -- Any tokenizer function, from word to sentence to tweet.\n",
    "                 Tokenizer must not be an object.method unless you\n",
    "                 specifiy it to be like TweetTokenizer.tokenize.\n",
    "                 Sentence tokenizer is initialized here.\n",
    "                 \n",
    "    rm_stop   -- Bool. Remove stop words or not.\n",
    "    \"\"\"\n",
    "\n",
    "    #remove line breaks\n",
    "    text = re.sub(r\"\\n\",\"\",text)\n",
    "    #remove trailing spaces\n",
    "    text = re.sub(r'[ \\t]+$','', text)\n",
    "    #convert to lowercase \n",
    "    text = text.lower()\n",
    "    #remove digits and currencies \n",
    "    text = re.sub(r\"\\d+\",\"\",text) \n",
    "    text = re.sub(r'[\\$\\d+\\d+\\$]', \"\", text)\n",
    "    #remove dates \n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    #remove non-ascii\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text) \n",
    "    # Replacing all links with standard link\n",
    "    #text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text) \n",
    "    #text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(link_regex, \"http://t.co\", text)\n",
    "    # separate out mention symbol from text so that models can learn from number of mentions\n",
    "    p = re.compile(mention_regex)\n",
    "    text = p.sub(r'@ \\1',text)\n",
    "\n",
    "    # separate out hashtag symbol from hashtag so that models can learn from number of hashtags\n",
    "    q = re.compile(hashtag_regex)\n",
    "    text = q.sub(r'# \\1',text)\n",
    "    \n",
    "    # remove retweet indicator text as it's rarely used\n",
    "    text = re.sub(retweet_indicator, \"\", text)\n",
    "    \n",
    "    #remove punctuation\n",
    "    # Leave it? or talking point?!\n",
    "    #text = re.sub(r'[^\\w\\s]','',text)\n",
    "    \n",
    "    if rm_stop:\n",
    "        filtered_tokens = [word for word in tokenizer(text) \n",
    "                           if not word in set(stopwords.words('english'))]\n",
    "        text = \" \".join(filtered_tokens)\n",
    "        \n",
    "    if method == 'l':\n",
    "        lemmer = WordNetLemmatizer()\n",
    "        lemm_tokens = [lemmer.lemmatize(word) \n",
    "                       for word in tokenizer(text)]\n",
    "        return \" \".join(lemm_tokens)\n",
    "    \n",
    "    elif method == 's':\n",
    "        porter = PorterStemmer()\n",
    "        stem_tokens = [porter.stem(word) \n",
    "                       for word in tokenizer(text)]\n",
    "        return \" \".join(stem_tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e8e9a",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9c5e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df\n",
    "train_labels = train_data.target\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c9126bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_model_on_preprocessed_text(preprocessed_text):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    transformed_data = tfidf.fit_transform(preprocessed_text)\n",
    "    model = MultinomialNB(alpha=0.9) # Best alpha from project 3\n",
    "    accuracy_scores = cross_val_score(model, transformed_data, train_labels, scoring='accuracy', cv=cv)\n",
    "    f1_scores = cross_val_score(model, transformed_data, train_labels, scoring='f1', cv=cv)\n",
    "    print('Accuracy: %.3f (%.3f)' % (mean(accuracy_scores), std(accuracy_scores)))\n",
    "    print('F1 Scores: %.3f (%.3f)' % (mean(f1_scores), std(f1_scores)))\n",
    "\n",
    "def preprocess_text():\n",
    "    return [preprocess(i) for i in train_data.text]\n",
    "    \n",
    "def preprocess_text_with_additional_cleaning(tokenizer):\n",
    "    return [preprocess(i,method='s',tokenizer=tokenizer,rm_stop=True) for i in train_data.text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4948e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_model_on_transformed_data(model, transformed_data, params):\n",
    "    print(\"Fitting GridSearch to optimize accuracy (this takes a while)...\")\n",
    "    accuracy_gridsearch_model = fit_gridsearch_model(model, transformed_data, params, 'accuracy')\n",
    "    print(\"Fitting GridSearch to optimize f1 score (this takes a while)...\")\n",
    "    f1_gridsearch_model = fit_gridsearch_model(model, transformed_data, params, 'f1')\n",
    "\n",
    "    print('Best params for accuracy: ', accuracy_gridsearch_model.best_params_)\n",
    "    print('Best mean score for accuracy: {:.2%}'.format(accuracy_gridsearch_model.best_score_))\n",
    "\n",
    "    print('Best params for f1: ', f1_gridsearch_model.best_params_)\n",
    "    print('Best mean score for f1: {:.2%}'.format(f1_gridsearch_model.best_score_))\n",
    "    \n",
    "def fit_gridsearch_model(model, data, params, scoring):\n",
    "    gridsearch_model = GridSearchCV(model, param_grid=params, cv=cv, scoring=scoring, n_jobs=-1, verbose=3)\n",
    "    return gridsearch_model.fit(data, train_labels)\n",
    "\n",
    "def transform_data_with_count_vectorizer(preprocessed_text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    return vectorizer.fit_transform(preprocessed_text)\n",
    "       \n",
    "def transform_data_with_tfidf(preprocessed_text):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    return tfidf.fit_transform(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9a7f219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GridSearch to optimize accuracy (this takes a while)...\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting GridSearch to optimize f1 score (this takes a while)...\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-7b3bd63041b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m          }\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mrun_model_on_transformed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_for_gmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vectorizer_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mrun_model_on_transformed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_for_gmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mrun_model_on_transformed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_for_gmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_transformed_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-06b0e7f073ee>\u001b[0m in \u001b[0;36mrun_model_on_transformed_data\u001b[0;34m(model, transformed_data, params)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maccuracy_gridsearch_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_gridsearch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting GridSearch to optimize f1 score (this takes a while)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mf1_gridsearch_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_gridsearch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best params for accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_gridsearch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-06b0e7f073ee>\u001b[0m in \u001b[0;36mfit_gridsearch_model\u001b[0;34m(model, data, params, scoring)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_gridsearch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mgridsearch_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgridsearch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_data_with_count_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/berkeley/berkeley/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/berkeley/berkeley/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/berkeley/berkeley/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/berkeley/berkeley/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/berkeley/berkeley/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/berkeley/berkeley/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/berkeley/berkeley/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "preprocessed_text = preprocess_text()\n",
    "preprocessed_text_with_additional_cleaning = preprocess_text_with_additional_cleaning(word_tokenize)\n",
    "\n",
    "tfidf_transformed = transform_data_with_tfidf(preprocessed_text)\n",
    "count_vectorizer_transformed = transform_data_with_count_vectorizer(preprocessed_text)\n",
    "\n",
    "tfidf_transformed_cleaned = transform_data_with_tfidf(preprocessed_text_with_additional_cleaning)\n",
    "count_vectorizer_transformed_cleaned = transform_data_with_count_vectorizer(preprocessed_text_with_additional_cleaning)\n",
    "\n",
    "def svd_for_gmm(vectorized_text):\n",
    "    svd = TruncatedSVD()\n",
    "    return svd.fit_transform(vectorized_text)\n",
    "\n",
    "def run_model_on_transformed_data_gmm(model, transformed_data, params):\n",
    "    print(\"Fitting GridSearch to optimize accuracy (this takes a while)...\")\n",
    "    accuracy_gridsearch_model = fit_gridsearch_model(model, transformed_data, params, 'accuracy',average='weighted')\n",
    "    print(\"Fitting GridSearch to optimize f1 score (this takes a while)...\")\n",
    "    f1_gridsearch_model = fit_gridsearch_model(model, transformed_data, params, 'f1', average='weighted')\n",
    "\n",
    "    print('Best params for accuracy: ', accuracy_gridsearch_model.best_params_)\n",
    "    print('Best mean score for accuracy: {:.2%}'.format(accuracy_gridsearch_model.best_score_))\n",
    "\n",
    "    print('Best params for f1: ', f1_gridsearch_model.best_params_)\n",
    "    print('Best mean score for f1: {:.2%}'.format(f1_gridsearch_model.best_score_))\n",
    "gmm    = GaussianMixture(random_state=12345)\n",
    "params = {\n",
    "          'covariance_type' : ['spherical', 'diag', 'tied', 'full'],\n",
    "          'n_components'    : [1, 2, 4, 6,10],\n",
    "         }\n",
    "\n",
    "run_model_on_transformed_data(gmm, svd_for_gmm(count_vectorizer_transformed), params)\n",
    "run_model_on_transformed_data(gmm, svd_for_gmm(tfidf_transformed), params)\n",
    "run_model_on_transformed_data(gmm, svd_for_gmm(tfidf_transformed_cleaned), params)\n",
    "run_model_on_transformed_data(gmm, svd_for_gmm(count_vectorizer_transformed_cleaned), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f21f5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7613x16378 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 104109 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer_transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba37f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy no text stripping w/ sw: 65.31%\n",
      "Accuracy no text stripping w/o sw: 65.31%\n",
      "Accuracy lemmatize w/SW: 65.31%\n",
      "Accuracy lemmatize w/o SW: 65.31%\n",
      "Accuracy stem w/ SW: 64.65%\n",
      "Accuracy stem w/o SW: 64.65%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TESTING no text stripping\n",
    "np.random.seed(0)\n",
    "df_ = df.sample(frac=1).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "#Split training data into disaster vs non-disaster\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "test_ = tfidf.transform(test_data)\n",
    "svd = TruncatedSVD()\n",
    "t_data = svd.fit_transform(t_data)\n",
    "test_ = svd.transform(test_)\n",
    "\n",
    "t_data_d = t_data[train_labels==1]\n",
    "t_data_nd = t_data[train_labels==0]\n",
    "\n",
    "\n",
    "# Create two gmm models, one for each class\n",
    "# implement GridSearchCV\n",
    "gmm_d = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_d)\n",
    "\n",
    "\n",
    "\n",
    "gmm_nd = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_nd)\n",
    "\n",
    "\n",
    "# Compute log probabilities and run np.exp on them \n",
    "# to get the probabilities.\n",
    "p_disaster = np.exp(gmm_d.score_samples(test_))\n",
    "np_disaster = np.exp(gmm_nd.score_samples(test_))\n",
    "\n",
    "# Use boolean np.where checker to get predicted labels given by gmm\n",
    "# Display accuracy score after.\n",
    "preds = np.where(p_disaster > np_disaster, 1, 0)\n",
    "print('Accuracy {}: {:.2f}%'.format('no text stripping w/ sw', metrics.accuracy_score(test_labels, preds)*100))\n",
    "\n",
    "\n",
    "# no text stripping w/o SW\n",
    "\n",
    "np.random.seed(0)\n",
    "df_ = df.sample(frac=1).reset_index()\n",
    "\n",
    "processed_full = []\n",
    "for i in df_.text:\n",
    "    processed_full.append(preprocess(i,rm_stop=True))\n",
    "df_.text = processed_full\n",
    "numtest = int(len(df_)/5)\n",
    "df_train = df_[numtest:].reset_index(drop=True)\n",
    "df_test = df_[:numtest].reset_index(drop=True)\n",
    "\n",
    "train_data, train_labels = df_train.text, df_train.target\n",
    "test_data, test_labels = df_test.text, df_test.target\n",
    "\n",
    "#Split training data into disaster vs non-disaster\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "test_ = tfidf.transform(test_data)\n",
    "svd = TruncatedSVD()\n",
    "t_data = svd.fit_transform(t_data)\n",
    "test_ = svd.transform(test_)\n",
    "\n",
    "t_data_d = t_data[train_labels==1]\n",
    "t_data_nd = t_data[train_labels==0]\n",
    "\n",
    "# Create two gmm models, one for each class\n",
    "# implement GridSearchCV\n",
    "gmm_d = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_d)\n",
    "\n",
    "gmm_nd = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_nd)\n",
    "\n",
    "\n",
    "# Compute log probabilities and run np.exp on them \n",
    "# to get the probabilities.\n",
    "p_disaster = np.exp(gmm_d.score_samples(test_))\n",
    "np_disaster = np.exp(gmm_nd.score_samples(test_))\n",
    "\n",
    "# Use boolean np.where checker to get predicted labels given by gmm\n",
    "# Display accuracy score after.\n",
    "preds = np.where(p_disaster > np_disaster, 1, 0)\n",
    "print('Accuracy {}: {:.2f}%'.format('no text stripping w/o sw', metrics.accuracy_score(test_labels, preds)*100))\n",
    "\n",
    "\n",
    "\n",
    "# Lemmatize no stop word removal\n",
    "np.random.seed(0)\n",
    "df_ = df.sample(frac=1).reset_index()\n",
    "\n",
    "processed_full = []\n",
    "for i in df_.text:\n",
    "    processed_full.append(preprocess(i,method='l'))\n",
    "df_.text = processed_full\n",
    "numtest = int(len(df_)/5)\n",
    "df_train = df_[numtest:].reset_index(drop=True)\n",
    "df_test = df_[:numtest].reset_index(drop=True)\n",
    "\n",
    "train_data, train_labels = df_train.text, df_train.target\n",
    "test_data, test_labels = df_test.text, df_test.target\n",
    "\n",
    "#Split training data into disaster vs non-disaster\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "test_ = tfidf.transform(test_data)\n",
    "svd = TruncatedSVD()\n",
    "t_data = svd.fit_transform(t_data)\n",
    "test_ = svd.transform(test_)\n",
    "\n",
    "t_data_d = t_data[train_labels==1]\n",
    "t_data_nd = t_data[train_labels==0]\n",
    "\n",
    "\n",
    "# Create two gmm models, one for each class\n",
    "# implement GridSearchCV\n",
    "gmm_d = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_d)\n",
    "\n",
    "gmm_nd = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_nd)\n",
    "\n",
    "\n",
    "# Compute log probabilities and run np.exp on them \n",
    "# to get the probabilities.\n",
    "p_disaster = np.exp(gmm_d.score_samples(test_))\n",
    "np_disaster = np.exp(gmm_nd.score_samples(test_))\n",
    "\n",
    "# Use boolean np.where checker to get predicted labels given by gmm\n",
    "# Display accuracy score after.\n",
    "preds = np.where(p_disaster > np_disaster, 1, 0)\n",
    "print('Accuracy {}: {:.2f}%'.format('lemmatize w/SW', metrics.accuracy_score(test_labels, preds)*100))\n",
    "\n",
    "# Lemmatize stop word removal\n",
    "np.random.seed(0)\n",
    "df_ = df.sample(frac=1).reset_index()\n",
    "\n",
    "processed_full = []\n",
    "for i in df_.text:\n",
    "    processed_full.append(preprocess(i,method='l', rm_stop=True))\n",
    "df_.text = processed_full\n",
    "numtest = int(len(df_)/5)\n",
    "df_train = df_[numtest:].reset_index(drop=True)\n",
    "df_test = df_[:numtest].reset_index(drop=True)\n",
    "\n",
    "train_data, train_labels = df_train.text, df_train.target\n",
    "test_data, test_labels = df_test.text, df_test.target\n",
    "\n",
    "#Split training data into disaster vs non-disaster\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "test_ = tfidf.transform(test_data)\n",
    "svd = TruncatedSVD()\n",
    "t_data = svd.fit_transform(t_data)\n",
    "test_ = svd.transform(test_)\n",
    "\n",
    "t_data_d = t_data[train_labels==1]\n",
    "t_data_nd = t_data[train_labels==0]\n",
    "\n",
    "\n",
    "# Create two gmm models, one for each class\n",
    "# implement GridSearchCV\n",
    "gmm_d = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_d)\n",
    "\n",
    "gmm_nd = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_nd)\n",
    "\n",
    "\n",
    "# Compute log probabilities and run np.exp on them \n",
    "# to get the probabilities.\n",
    "p_disaster = np.exp(gmm_d.score_samples(test_))\n",
    "np_disaster = np.exp(gmm_nd.score_samples(test_))\n",
    "\n",
    "# Use boolean np.where checker to get predicted labels given by gmm\n",
    "# Display accuracy score after.\n",
    "preds = np.where(p_disaster > np_disaster, 1, 0)\n",
    "print('Accuracy {}: {:.2f}%'.format('lemmatize w/o SW', metrics.accuracy_score(test_labels, preds)*100))\n",
    "\n",
    "# stemmatize w/o stop word removal\n",
    "np.random.seed(0)\n",
    "df_ = df.sample(frac=1).reset_index()\n",
    "\n",
    "processed_full = []\n",
    "for i in df_.text:\n",
    "    processed_full.append(preprocess(i,method='s', rm_stop=False))\n",
    "df_.text = processed_full\n",
    "numtest = int(len(df_)/5)\n",
    "df_train = df_[numtest:].reset_index(drop=True)\n",
    "df_test = df_[:numtest].reset_index(drop=True)\n",
    "\n",
    "train_data, train_labels = df_train.text, df_train.target\n",
    "test_data, test_labels = df_test.text, df_test.target\n",
    "\n",
    "#Split training data into disaster vs non-disaster\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "test_ = tfidf.transform(test_data)\n",
    "svd = TruncatedSVD()\n",
    "t_data = svd.fit_transform(t_data)\n",
    "test_ = svd.transform(test_)\n",
    "\n",
    "t_data_d = t_data[train_labels==1]\n",
    "t_data_nd = t_data[train_labels==0]\n",
    "\n",
    "\n",
    "# Create two gmm models, one for each class\n",
    "# implement GridSearchCV\n",
    "gmm_d = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_d)\n",
    "\n",
    "gmm_nd = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_nd)\n",
    "\n",
    "\n",
    "# Compute log probabilities and run np.exp on them \n",
    "# to get the probabilities.\n",
    "p_disaster = np.exp(gmm_d.score_samples(test_))\n",
    "np_disaster = np.exp(gmm_nd.score_samples(test_))\n",
    "\n",
    "# Use boolean np.where checker to get predicted labels given by gmm\n",
    "# Display accuracy score after.\n",
    "preds = np.where(p_disaster > np_disaster, 1, 0)\n",
    "print('Accuracy {}: {:.2f}%'.format('stem w/ SW', metrics.accuracy_score(test_labels, preds)*100))\n",
    "\n",
    "\n",
    "# stemmatize w stop word removal\n",
    "np.random.seed(0)\n",
    "df_ = df.sample(frac=1).reset_index()\n",
    "\n",
    "processed_full = []\n",
    "for i in df_.text:\n",
    "    processed_full.append(preprocess(i,method='s', rm_stop=True))\n",
    "df_.text = processed_full\n",
    "numtest = int(len(df_)/5)\n",
    "df_train = df_[numtest:].reset_index(drop=True)\n",
    "df_test = df_[:numtest].reset_index(drop=True)\n",
    "\n",
    "train_data, train_labels = df_train.text, df_train.target\n",
    "test_data, test_labels = df_test.text, df_test.target\n",
    "\n",
    "#Split training data into disaster vs non-disaster\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "test_ = tfidf.transform(test_data)\n",
    "svd = TruncatedSVD()\n",
    "t_data = svd.fit_transform(t_data)\n",
    "test_ = svd.transform(test_)\n",
    "\n",
    "t_data_d = t_data[train_labels==1]\n",
    "t_data_nd = t_data[train_labels==0]\n",
    "\n",
    "\n",
    "# Create two gmm models, one for each class\n",
    "# implement GridSearchCV\n",
    "gmm_d = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_d)\n",
    "\n",
    "gmm_nd = GaussianMixture(n_components=10,\n",
    "                            covariance_type='full', \n",
    "                            random_state=12345).fit(t_data_nd)\n",
    "\n",
    "\n",
    "# Compute log probabilities and run np.exp on them \n",
    "# to get the probabilities.\n",
    "p_disaster = np.exp(gmm_d.score_samples(test_))\n",
    "np_disaster = np.exp(gmm_nd.score_samples(test_))\n",
    "\n",
    "# Use boolean np.where checker to get predicted labels given by gmm\n",
    "# Display accuracy score after.\n",
    "preds = np.where(p_disaster > np_disaster, 1, 0)\n",
    "print('Accuracy {}: {:.2f}%'.format('stem w/o SW', metrics.accuracy_score(test_labels, preds)*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffda279",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-59ee9e56a4f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Naive Bayes example run, using non clustered data first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dev' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocess data-> split normally\n",
    "# set random seed\n",
    "# preprocess data-> split normally\n",
    "# set random seed\n",
    "\n",
    "np.random.seed(0)\n",
    "df_ = df.sample(frac=1).reset_index()\n",
    "\n",
    "processed_full = []\n",
    "for i in df_.text:\n",
    "    processed_full.append(preprocess(i))\n",
    "df_.text = processed_full\n",
    "\n",
    "# numtest = int(len(df_)/3.5)\n",
    "# df_test = df_[:int(numtest/2)].reset_index(drop=True)\n",
    "# df_dev = df_[int(numtest/2):numtest].reset_index(drop=True)\n",
    "numtest = int(len(df_)/5)\n",
    "df_train = df_[numtest:].reset_index(drop=True)\n",
    "df_test = df_[:numtest].reset_index(drop=True)\n",
    "\n",
    "train_data, train_label = np.array(df_train.text), np.array(df_train.target)\n",
    "dev_data, dev_label = np.array(df_dev.text), np.array(df_dev.target)\n",
    "test_data, test_label = np.array(df_test.text), np.array(df_test.target)\n",
    "# Naive Bayes example run, using non clustered data first.\n",
    "# I'll use TF-IDF in this to vectorize data.\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "dt_data = tfidf.transform(dev_data)\n",
    "tt_data = tfidf.transform(test_data)\n",
    "m_nb = MultinomialNB(alpha=0.9).fit(t_data, train_label) # best alpha from project 3\n",
    "pred = m_nb.predict(dt_data)\n",
    "pred_test = m_nb.predict(tt_data)\n",
    "print('Test on no word root strip:')\n",
    "print('F1 Score: {:.4f}'.format(metrics.f1_score(test_label, pred_test, average='weighted')))\n",
    "print('Accuracy: {:.4f}'.format(metrics.accuracy_score(test_label, pred_test)))\n",
    "print()\n",
    "\n",
    "tokenizer = word_tokenize\n",
    "np.random.seed(0)\n",
    "df_ = df.sample(frac=1).reset_index()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed_full = []\n",
    "for i in df_.text:\n",
    "    processed_full.append(preprocess(i,method='s',tokenizer=tokenizer))\n",
    "df_.text = processed_full\n",
    "\n",
    "# numtest = int(len(df_)/3.5)\n",
    "# df_test = df_[:int(numtest/2)].reset_index(drop=True)\n",
    "# df_dev = df_[int(numtest/2):numtest].reset_index(drop=True)\n",
    "numtest = int(len(df_)/5)\n",
    "df_train = df_[numtest:].reset_index(drop=True)\n",
    "df_test = df_[:numtest].reset_index(drop=True)\n",
    "\n",
    "train_data, train_label = np.array(df_train.text), np.array(df_train.target)\n",
    "dev_data, dev_label = np.array(df_dev.text), np.array(df_dev.target)\n",
    "test_data, test_label = np.array(df_test.text), np.array(df_test.target)\n",
    "# Naive Bayes example run, using non clustered data first.\n",
    "# I'll use TF-IDF in this to vectorize data.\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "dt_data = tfidf.transform(dev_data)\n",
    "tt_data = tfidf.transform(test_data)\n",
    "m_nb = MultinomialNB(alpha=0.9).fit(t_data, train_label) # best alpha from project 3\n",
    "pred = m_nb.predict(dt_data)\n",
    "pred_test = m_nb.predict(tt_data)\n",
    "print('Test on Stemmatize:')\n",
    "print('F1 Score: {:.4f}'.format(metrics.f1_score(test_label, pred_test, average='weighted')))\n",
    "print('Accuracy: {:.4f}'.format(metrics.accuracy_score(test_label, pred_test)))\n",
    "\n",
    "# preprocess data-> split normally\n",
    "# set random seed\n",
    "\n",
    "# # stem\n",
    "# studies -> studi\n",
    "# study -> stud\n",
    "# # lemm\n",
    "# studies -> study\n",
    "# study -> study\n",
    "\n",
    "tokenizer = word_tokenize\n",
    "\n",
    "np.random.seed(0)\n",
    "df_ = df.sample(frac=1).reset_index()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed_full = []\n",
    "for i in df_.text:\n",
    "    processed_full.append(preprocess(i,method='l',tokenizer=tokenizer))\n",
    "df_.text = processed_full\n",
    "\n",
    "# numtest = int(len(df_)/3.5)\n",
    "# df_test = df_[:int(numtest/2)].reset_index(drop=True)\n",
    "# df_dev = df_[int(numtest/2):numtest].reset_index(drop=True)\n",
    "numtest = int(len(df_)/5)\n",
    "df_train = df_[numtest:].reset_index(drop=True)\n",
    "df_test = df_[:numtest].reset_index(drop=True)\n",
    "\n",
    "train_data, train_label = np.array(df_train.text), np.array(df_train.target)\n",
    "dev_data, dev_label = np.array(df_dev.text), np.array(df_dev.target)\n",
    "test_data, test_label = np.array(df_test.text), np.array(df_test.target)\n",
    "# Naive Bayes example run, using non clustered data first.\n",
    "# I'll use TF-IDF in this to vectorize data.\n",
    "\n",
    "tfidf = CountVectorizer(ngram_range=(1,1))\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "dt_data = tfidf.transform(dev_data)\n",
    "tt_data = tfidf.transform(test_data)\n",
    "m_nb = MultinomialNB(alpha=0.9).fit(t_data, train_label) # best alpha from project 3\n",
    "pred = m_nb.predict(dt_data)\n",
    "pred_test = m_nb.predict(tt_data)\n",
    "print()\n",
    "print('Test on Lemmatize:')\n",
    "print('F1 Score: {:.4f}'.format(metrics.f1_score(test_label, pred_test, average='weighted')))\n",
    "print('Accuracy: {:.4f}'.format(metrics.accuracy_score(test_label, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_boot(df, n_clusters=2):\n",
    "    # Must accept pre-processed data as DF\n",
    "    \n",
    "    \"\"\" Pre-Cluster data before splitting to enhance generalization\"\"\"\n",
    "    dat = df.text\n",
    "    tfidf = TfidfVectorizer()\n",
    "    t_data = tfidf.fit_transform(dat)\n",
    "    # pca = \n",
    "    cluster = KMeans(n_clusters=n_clusters).fit(t_data) # really bad clustering for loo\n",
    "    df['assign'] = cluster.labels_\n",
    "    \n",
    "    if n_clusters == 2:\n",
    "        if len(df[df['assign']==1]) > len(df[df['assign']==0]):\n",
    "            s, l = 0, 1\n",
    "        else:\n",
    "            s, l = 1, 0\n",
    "        len_valid = int(len(df[df['assign']==s])/2)\n",
    "        df_test = df[df['assign']==s][:len_valid].reset_index(drop=True)\n",
    "        df_dev = df[df['assign']==s][len_valid:].reset_index(drop=True)\n",
    "        df_train = df[df['assign']==l].reset_index(drop=True)\n",
    "    else:\n",
    "        groups = [] # list of two tuples of clusters\n",
    "        centroids = cluster.cluster_centers_\n",
    "    \n",
    "    # Simple prelim:: Sparse matrix for Spectral Clustering\n",
    "    # if cluster is more than 2 then use the majority of clusters\n",
    "    # closest to each other as training set and the rest as dev/test\n",
    "    # notes: this method did not work, the spectral takes too long for\n",
    "    # this size of a sparse matrix.\n",
    "    #     elif typ == 'cv':\n",
    "    #         cv = CountVectorizer()\n",
    "    #         t_data = cv.fit_transform(dat)\n",
    "    #         cluster = SpectralClustering(n_clusters=2).fit(t_data)\n",
    "    return (df_train, df_dev, df_test)\n",
    "\n",
    "df_train,df_dev,df_test = cluster_boot(df_)\n",
    "train_data, train_label = np.array(df_train.text), np.array(df_train.target)\n",
    "dev_data, dev_label = np.array(df_dev.text), np.array(df_dev.target)\n",
    "test_data, test_label = np.array(df_test.text), np.array(df_test.target)\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "dt_data = tfidf.transform(dev_data)\n",
    "tt_data = tfidf.transform(test_data)\n",
    "m_nb = MultinomialNB(alpha=0.9).fit(t_data, train_label) # best alpha from project 3\n",
    "pred = m_nb.predict(dt_data)\n",
    "pred_t = m_nb.predict(tt_data)\n",
    "print('Metrics by cluster-splitting')\n",
    "print('F1 Score: {:.4f}'.format(metrics.f1_score(dev_label, pred, average='weighted')))\n",
    "print('Accuracy: {:.4f}'.format(metrics.accuracy_score(dev_label, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a586b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bbd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING \n",
    "dat = df_.text\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(dat)\n",
    "# not doing LSA, performing SVD is only for sake of cluster.. \n",
    "# due to very sparse data it is difficult to cluster on KMeans, \n",
    "# so we SVD I.E sparse->sparse to reduce dimensions\n",
    "svd = TruncatedSVD()\n",
    "t_data = svd.fit_transform(t_data)\n",
    "cluster = KMeans(n_clusters=2).fit(t_data) # really bad clustering for loo\n",
    "\n",
    "df['assign'] = cluster.labels_\n",
    "if len(df[df['assign']==1]) > len(df[df['assign']==0]):\n",
    "    s, l = 0, 1\n",
    "else:\n",
    "    s, l = 1, 0\n",
    "len_valid = int(len(df[df['assign']==s])/2)\n",
    "df_test = df[df['assign']==s][:len_valid].reset_index(drop=True)\n",
    "df_dev = df[df['assign']==s][len_valid:].reset_index(drop=True)\n",
    "df_train = df[df['assign']==l].reset_index(drop=True)\n",
    "\n",
    "train_data, train_label = np.array(df_train.text), np.array(df_train.target)\n",
    "dev_data, dev_label = np.array(df_dev.text), np.array(df_dev.target)\n",
    "test_data, test_label = np.array(df_test.text), np.array(df_test.target)\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(train_data)\n",
    "dt_data = tfidf.transform(dev_data)\n",
    "tt_data = tfidf.transform(test_data)\n",
    "m_nb = MultinomialNB(alpha=0.9).fit(t_data, train_label) # best alpha from project 3\n",
    "pred = m_nb.predict(dt_data)\n",
    "pred_t = m_nb.predict(tt_data)\n",
    "print('Metrics by cluster-splitting')\n",
    "print('F1 Score: {:.4f}'.format(metrics.f1_score(dev_label, pred, average='weighted')))\n",
    "print('Accuracy: {:.4f}'.format(metrics.accuracy_score(dev_label, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c863f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = df.text\n",
    "tfidf = TfidfVectorizer()\n",
    "t_data = tfidf.fit_transform(dat)\n",
    "# not doing LSA, performing SVD is only for sake of cluster.. \n",
    "# due to very sparse data it is difficult to cluster on KMeans, \n",
    "# so we SVD I.E sparse->sparse to reduce dimensions\n",
    "svd = TruncatedSVD()\n",
    "t_data = svd.fit_transform(t_data)\n",
    "cluster = KMeans(n_clusters=6).fit(t_data) # really bad clustering for loo\n",
    "cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cff311",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.spy(t_data,markersize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e04b8",
   "metadata": {},
   "source": [
    "# reference\n",
    "https://necromuralist.github.io/Neurotic-Networking/posts/nlp/01-twitter-preprocessing-with-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0da0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berkeley",
   "language": "python",
   "name": "berkeley"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
